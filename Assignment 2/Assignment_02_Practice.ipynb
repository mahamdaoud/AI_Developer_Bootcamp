{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f8317c-87bd-4be4-ba32-f538be9c8625",
   "metadata": {},
   "source": [
    "## Step 1 : Text Cleaning and Preprocessing\n",
    "#### The below lines of code are used for text cleaning in NLP.\n",
    "- It will convert the text into lower case.\n",
    "- And it will deleted all the punctuation marks in the text.\n",
    "- It will also delete all the numbers and white spaces.\n",
    "- It will output simple text in lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d22ee-1f2f-497a-88e8-0226e3b1bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning is fun'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    #convert to lower case\n",
    "    text = text.lower()\n",
    "    #remove punctuation\n",
    "    text = text.translate(str.maketrans('','', string.punctuation)) # two single quotes \n",
    "    #Remove numbers\n",
    "    text = re.sub(r'\\d+','', text)\n",
    "    #Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "clean_text(\"Machine Learning is Fun! <3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ba131-6aa5-4279-bb1a-2771a4a14f7f",
   "metadata": {},
   "source": [
    "## Step 2 : Tokenization and Stop Word Removal\n",
    "#### The below code will tokenize and remove the stop words from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9747a40-f546-44e5-8b21-44a548cddd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    #Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    #Remove Stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "tokenize_text(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955f1f63-612e-4ab4-8ca5-75d230743195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine', 'learning', 'fun']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text(clean_text((\"Machine learning is fun!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba4e6f-7fa7-4f40-8933-660abc073b33",
   "metadata": {},
   "source": [
    "## Step 3 : Feature Extraction - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c9727-80ac-49b0-a440-861472da4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2adf5474-2a87-4f50-8766-161eae692697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "documents = [\n",
    "    \"I love programming in Python.\",\n",
    "    \"Python is great for data science.\",\n",
    "    \"I enjoy learning new Python libraries.\",\n",
    "    \"Machine learning is fun!\"\n",
    "]\n",
    "\n",
    "\n",
    "#create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 1000, ngram_range=(1,2), min_df = 2, max_df = 0.8)\n",
    "#Fit and Transform\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20655432-e42c-49e4-9937-d8093e901726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672d3789-78c6-4786-a26e-b741e5840b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['is', 'learning', 'python'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c994a584-3fb7-49a7-84c8-d4d00a51b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777221</td>\n",
       "      <td>0.629228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is  learning    python\n",
       "0  0.000000  0.000000  1.000000\n",
       "1  0.777221  0.000000  0.629228\n",
       "2  0.000000  0.777221  0.629228\n",
       "3  0.707107  0.707107  0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Show the table\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e4326-55aa-4025-9c1f-2a2866617476",
   "metadata": {},
   "source": [
    "## Step 4 Advanced Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f4ee20-878e-4f99-828e-166a1294d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    features = {}\n",
    "    # Basic statistics \n",
    "    features['char_count'] = len(text)\n",
    "    features['word_count'] = len(text.split())\n",
    "    features['sentence_count'] = text.count('.') + text.count('!') + text.count('?')\n",
    "    #Advanced Features\n",
    "    features['avg_word_length'] = sum(len(word) for word in text.split()) / len(text.split())\n",
    "    features['unique_words'] = len(set(text.split()))\n",
    "    features['lexical_diversity'] = features['unique_words'] / features['word_count']\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f22826-586d-4690-aba2-0ad96bc3680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_count': 24,\n",
       " 'word_count': 4,\n",
       " 'sentence_count': 1,\n",
       " 'avg_word_length': 5.25,\n",
       " 'unique_words': 4,\n",
       " 'lexical_diversity': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_features(\"Machine learning is fun.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ba42c-7320-494b-b224-7e8ac0d52f73",
   "metadata": {},
   "source": [
    "## Both the two cells are have same code but a little different syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456281ad-7016-49cf-89e7-ff8134dea075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', 'Maham', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization and removing the stop words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def Tokenize_Text(text):\n",
    "    #tokenizing the data\n",
    "    tokens = word_tokenize(text)\n",
    "    #setting the stop words to english stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    new_tokens =[]\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens\n",
    "Tokenize_Text(\"My name is Maham.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d770b527-ce7a-4623-9106-439176037c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', 'Maham', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization and removing the stop words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def Tokenize_Text(text):\n",
    "    #tokenizing the data\n",
    "    tokens = word_tokenize(text)\n",
    "    #setting the stop words to english stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "Tokenize_Text(\"My name is Maham.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d306bb-c1ea-48a1-9922-a6ae9137e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_mark_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  sentence_count  exclamation_count  \\\n",
       "1          17           4               1                  0   \n",
       "\n",
       "   question_mark_count  hashtag_count  mentions_count  avg_word_length  \n",
       "1                    0              0               0              3.5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def extract_features(text):\n",
    "    features ={}\n",
    "    words = text.split()\n",
    "    features['char_count'] = len(text)\n",
    "    features['word_count'] = len(words)\n",
    "    features['sentence_count'] =text.count('.') + text.count('!') + text.count('?')\n",
    "    features['exclamation_count'] = text.count('!')\n",
    "    features['question_mark_count'] = text.count('?')\n",
    "    features['hashtag_count'] = text.count('#')\n",
    "    features['mentions_count'] = text.count('@')\n",
    "    features['avg_word_length'] = sum(len(word) for word in words) / len(words) if len(words) > 0 else 0\n",
    "    return features\n",
    "feature = extract_features(\"My name is Maham.\")\n",
    "df = pd.DataFrame(feature, index =[1])\n",
    "df\n",
    "#data['features']= data['text'].apply(extract_features)\n",
    "#data = pd.concat([data,features], axis = 1)\n",
    "#data[['text', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a23afe-b3ef-495a-ba49-0f9391e722f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
